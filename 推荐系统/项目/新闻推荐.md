新闻推荐

数据集：科大讯飞新闻推荐数据集

user_info_3w.csv
该文件共包含了3万条用户的个人数据；
特征分别包括了：['user_id', 'device', 'os', 'province', 'city', 'age', 'gender']；
各特征的含义为：['用户id', '设备名称', '操作系统', '所在省', '所在市', '年龄', '性别']；

doc_info.txt
该文件包含了10万新闻的特征数据；
各特征的含义为：['文档id', '标题', '发文时间', '图片数量', '一级分类', '二级分类', '关键词']；

train_data_3w.csv
该文件为用户点击数据，包含了3万个用户在过去13天的32万点击数据；
各特征的含义为：['用户id', '文档id', '展现时间', '网路环境', '刷新次数', '展现位置', '是否点击', '消费时长（秒）']；

用户画像：用户id，设备名称，操作系统，所在省，所在市，年龄，性别
新闻画像：文档id，标题，发文时间，图片数量，一级分类，二级分类，关键词

训练集：前12天数据
测试集：第13天数据

特征处理：

用户和文档特征：

用户数据处理：
性别：0未知，1男，2女
年龄：年龄段 0-10，10-20，20-30，30-40，40-50，50-60，60-70，70-80，80-90，90-100

文档数据处理：
发文时间整理：日期+时间 方便后续处理
缺失值处理：0填充、具体情况待定


统计特征：
1. 发文到曝光的平均时间差
2. 用户统计特征：统计每个用户过去几天的
   文档曝光数、不同类目文档曝光数
   整体点击率、不同类目点击率
   消费总时长、不同类目消费总时长
3. 文档统计特征：
   统计每个文档过去几天的曝光数、平均点击率、平均消费时长、消费总时长
   统计各类目文档过去几天的曝光数、平均点击率、平均消费时长、消费总时长



热门页推荐：曝光次数、点击次数、消费时长
    热度计算加权公式：H = 0.3 * 曝光次数 + 0.5 * 点击次数 + 0.2 * 消费时长
    H * 时间衰减因子D：1/（1 + 0.01 * 时间差）

多路召回：

类目召回：返回用户最近一次点击的一级类目相同的200个新闻（按发布时间倒排）

地域召回：返回用户所在省市的200个新闻（按发布时间倒排）如何区分新闻属于哪个省市？使用用户所在地热门新闻代替。
            看位于同一位置的用户交互过的新闻，视为该地区的热门新闻，取top 200个。（筛选最近3天的数据）


DSSM召回：DSSM+SENet+归一化、温度系数 RELU
SENet：
m个用户特征得到m*k个向量

平均池化 AvgPool 得到 m*1
全连接层 FC+ReLU 得到 m/r*1 压缩
全连接层 FC+Sigmoid 得到 m*1 恢复

最后
m*k个向量与 m*1向量逐行相乘 做加权

最后得到 m*k个向量

神经网络DNN层：RELU


编码：
1. 离散特征：性别、年龄、省、市、一级分类、二级分类、关键词
    one-hot编码： labelEncoder

2. 连续特征 主要是统计特征：发文时间、图片数量、发文到曝光的平均时间差、文档曝光数、点击数、消费时长
    word2vec编码： transformers
    归一化：
连续型特征包含的主要是统计特征，这里对于空值统一使用 0 进行填充；
之后，对所有的连续型特征进行对数归一化， 即取 log 对数；（防止大数影响模型效果）


训练方式：Pointwise
把召回看作二分类任务 （用户，物品）
对于正样本，鼓励cos(a,b)接近1
对于负样本，鼓励cos(a,b)接近-1
控制正负样本比例（1:2或1:3）（经验）
损失函数：sigmoid+交叉熵
sigmoid（cos(a,b)）大于0.5为正样本，小于0.5为负样本 loss：-[1 * log(sigmoid(cos(a,b))) + 0 * log(1 - sigmoid(cos(a,b)))]


排序：
DeepFM：

FM：二阶特征交叉
·FM是线性模型的替代品，能用线性回归、逻辑回归的场景，都可以用FM。
·FM 使用二阶交叉特征，表达能力比线性模型更强。
通过做近似 ui ≈ vi.vj，FM 把二阶交叉权重的参数数量从 0(d2)降低到 0(kd)（k<<d)，d 是特征维度，k 是隐向量的维度。

PPNet：
LHUC 算法：
物品向量+全连接
用户向量+全连接

二者哈达玛积 +全连接
用户向量+全连接

二者哈达玛积 +全连接
得到最终的非线性特征

sigmoid(linear_logits + fm_logits + deep_logits)
得到精排分数


重排：
MMR：最大化多样性 从未选中集合中选择和已选中集合最不相似的物品
    每次从候选物品集合中选出一个和已选物品物品集合相似性最弱且和用户相关性最强的物品
    滑动窗口：已选物品集合使用最近选择的k个物品
    MMR = θ * rewardi - (1 - θ) * maxsim(i,j)
    argmax MMR(i)
1.已选中的物品S初始化为空集，未选中的物品见初始化为全集{1,…,n}
2.选择精排分数rewardi最高的物品，从集合R移到Sc
3.做k-1轮循环:
a.计算集合见中所有物品的分数{MRi}ieR。
b.选出分数最高的物品，将其从见移到S

滑动窗口：
·已选中的物品越多(即集合S越大)，越难找出物品i，使得i与S中的物品都不相似。
设sim 的取值范围是[0,1。当S很大时，多样性分数maxsim(i,j)总是约等于1，导致 MMR 算法失效。
解决方案:设置一个滑动窗口W，比如最近选中的10个品，用W代替 MMR 公式中的S。

类目打散：起检查作用，防止推荐结果过于集中

我参与的这个项目主要多元时序数据的异常检测，针对在应对数据复杂性、异常类型多样性的问题，一种模型难以适用各种时序数据的异常检测方法，我们的想法是为不同数据集选择最合适的异常检测模型。在项目中，我们通过实证分析给出一些模型选择建议，统计各个数据集的平滑度、周期度、指标相关度的数据特征，统计全局异常、局部异常、周期性异常、趋势性异常的占比，作为异常类型的特征，通过这些数据特征，对应到最合适的异常检测模型，实现为为不同数据集选择最合适的异常检测模型。


自我介绍：
面试官您好，我叫李鹏，是南开大学软件工程专业21级的本科生，目前已经保研到中国科学院大学计算机学院。
本科期间，我的学习成绩专业排名大约是10%，获得过国家励志奖学金和三好学生等荣誉，获得过天津市人工智能电脑鼠大赛一等奖 和 全国大学生数学建模竞赛天津市二等奖。

专业技能方面，我熟练使用C++、Python和Linux进行开发，了解大数据开发工具。
熟悉常用的机器学习算法和推荐系统中的召回、排序算法，了解推荐系统的思想和整体架构。

在科研项目方面，我参与了南开大学AIOps实验室的多元时序数据异常检测项目，负责实证分析和模型超参数优化。通过模型集成和超参数优化，实现为不同数据选择最合适的异常检测模型，实现从数据到模型及其超参数的自适应选择。
在实践项目方面，我学习了Datewhale开源的推荐系统教程，实现新闻推荐系统。使用类目召回、地域召回和双塔模型实现多路召回，使用DeepFM模型对召回结果进行排序，结合类目打散和MMR算法进行重排，实现新闻的热门页推荐和个性化推荐。

我的介绍大概就是这些，谢谢！

https://guoleida.blog.csdn.net/article/details/84938102

